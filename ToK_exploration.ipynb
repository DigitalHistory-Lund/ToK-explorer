{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d9b68-dbde-4909-b6b2-345adea49bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tqdm pyriksdagen ipywidgets plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7036f8-9a84-4b9b-b3d0-38b8ca99df46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyparlaclarin.read import paragraph_iterator, speeches_with_name\n",
    "from pyriksdagen.utils import protocol_iterators, download_corpus\n",
    "\n",
    "from pathlib import Path\n",
    "from queue import Queue\n",
    "from lxml import etree\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import progressbar\n",
    "import pyriksdagen\n",
    "import ipywidgets\n",
    "\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "import re\n",
    "import os\n",
    "\n",
    "pyo.init_notebook_mode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4658de-d140-4369-9ac8-60f36e92f5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe9b7ed-54e2-4789-a9b7-259a700df5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(remove_blank_text=True)\n",
    "\n",
    "data_dir = Path('.').resolve() / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55e419-31a2-4bda-9731-a543cdcb67b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len([file for file in data_dir.iterdir() if file.is_file()]) < 25:\n",
    "    print('Did not find metadata files. Downloading.')\n",
    "    download_corpus(partitions=[\"persons\"])\n",
    "\n",
    "records_data_dir = data_dir / 'records'\n",
    "if len([subdir for subdir in data_dir.iterdir() if subdir.is_dir()]) < 158:\n",
    "    print('Did not find protocols files. Downloading.')\n",
    "    download_corpus(partitions=[\"records\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c458f3d-f7b8-4eb9-974a-730624dbdaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = list(sorted(protocol_iterators(corpus_root=\"data/\", start=1899, end=1941)))\n",
    "print(len(protocols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8302974-6a9d-4da6-8815-566695f109a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(protocols[0].split('/')[1][:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df9f12-bb03-4b1e-8d8b-747b09c4874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_roots(protocols):\n",
    "    for protocol in protocols:\n",
    "        year = int(protocol.split('/')[1][:4])\n",
    "        yield etree.parse(protocol, parser).getroot(), year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbebdb-253b-4372-9f79-805de3fc18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_root_queue(q: Queue):\n",
    "    \"\"\"\n",
    "    TODO: Extract debate names\n",
    "    TODO: Extract dates\n",
    "    \"\"\"\n",
    "    while not q.empty():\n",
    "        c, element, year = q.get()\n",
    "        if (who:= element.get('who')) is not None:\n",
    "            u_id = element.get([key for key in element.keys() if key.endswith('}id')][0])\n",
    "            assert u_id\n",
    "            prev = element.get('prev')\n",
    "            nxt = element.get('next')\n",
    "    \n",
    "            text = '\\n\\n'.join(re.sub(r'\\s+' ,' ', seg.text) for seg in element.getchildren())\n",
    "            yield u_id, prev, nxt, text, who, year\n",
    "        else:\n",
    "            for child in element.getchildren():\n",
    "                if (child.tag.endswith('note') or child.tag.endswith('seg')) and not bool(re.search(r'^\\S+dag', child.text)):\n",
    "                    continue\n",
    "                q.put((c+1, child, year))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206320d-2f9b-4067-ab71-76e8037f8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_utterances(protocols):\n",
    "    q = Queue()\n",
    "    for root, year in prepare_roots(protocols):\n",
    "        q.put((0,root, year))\n",
    "    yield from process_root_queue(q)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711daa53-a550-4125-a441-854baa16bedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_utterances = []\n",
    "for utterance in tqdm(extract_all_utterances(protocols), total=701_218): #total=5273785):\n",
    "    all_utterances.append(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010d810-cc3f-4828-ad7c-d02a6a96f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def batched(iterable, n, *, strict=False):\n",
    "    # batched('ABCDEFG', 2) â†’ AB CD EF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    iterator = iter(iterable)\n",
    "    while batch := tuple(islice(iterator, n)):\n",
    "        if strict and len(batch) != n:\n",
    "            raise ValueError('batched(): incomplete batch')\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addfe75-5a8b-44c9-8f87-1da689da42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_db = './tmp.db'\n",
    "if os.path.exists(tmp_db):\n",
    "    os.unlink(tmp_db)\n",
    "\n",
    "with sqlite3.connect(tmp_db) as conn:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('CREATE TABLE utterance (id str primary key, prev text, next text, who text, year int)')\n",
    "    # cur.execute(\"PRAGMA compile_options LIKE '%SQLITE_ENABLE_FTS5%';\")\n",
    "    cur.execute('CREATE VIRTUAL TABLE utterance_fts USING fts5(content)')\n",
    "    cur.execute('CREATE index next_index on utterance(next)')\n",
    "    cur.execute('CREATE index prev_index on utterance(prev)')\n",
    "    cur.execute('CREATE index who_index on utterance(who)')\n",
    "    cur.execute('CREATE index year_index on utterance(year)')\n",
    "\n",
    "    data = []\n",
    "    for batch in tqdm(batched(all_utterances, 50_000), total=len(all_utterances)//50_000):\n",
    "        data = [{'id':u_id, 'prev':prev, 'next':nxt, 'content':text, 'who':who, 'year':year} for u_id, prev, nxt, text, who, year in batch]\n",
    "        cur.executemany('INSERT INTO utterance_fts (content) values (:content)', data)\n",
    "        cur.executemany('INSERT INTO utterance (id, prev, next, who, year) values (:id, :prev, :next, :who, :year)', data)\n",
    "    \n",
    "        conn.commit()\n",
    "            \n",
    "    # TODO: Add speaker metadata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa43b8-445b-4ca7-b749-a23f9d47bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "term_counter = Counter()\n",
    "\n",
    "with sqlite3.connect(tmp_db) as conn:\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    \n",
    "    print(cur.execute('select count(*) from utterance_fts where content match \"kvinna AND kvinnor\"').fetchall())\n",
    "    print(cur.execute('select count(*) from utterance_fts where content match \"kvinna\"').fetchall())\n",
    "    print(cur.execute('select count(*) from utterance_fts where content match \"kvinnor\"').fetchall())\n",
    "    print(cur.execute('select count(*) from utterance_fts where content match \"kvinna OR kvinnor\"').fetchall())\n",
    "    print(cur.execute('select count(*) from utterance_fts where content match \"kvinn*\"').fetchall())\n",
    "\n",
    "    term_counter = Counter((token.lower() for content in cur.execute('select content from utterance_fts where content match \"kvinn*\"')\n",
    "        for token in content[0].split() if token.lower().startswith('kvinn')))\n",
    "            \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0731140f-0d3f-429a-8d96-40e14bcc6c85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "term_counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a8dc9-bc5f-432d-a41d-32a93e14c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeline(match_pattern: str) -> List[Tuple[int, int]]:\n",
    "    with sqlite3.connect(tmp_db) as conn:\n",
    "        cur = conn.cursor()\n",
    "    \n",
    "        return cur.execute(f'select year, count(*) from utterance as u join utterance_fts as uf on u.rowid == uf.rowid where content match \"{match_pattern}\" group by year').fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e896f33-475d-4b36-84c9-6715dbc6950e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a81215-bb82-4524-97c6-7844fe277486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_timeline(keywords : List[str]) -> List[Tuple[int, int]]:\n",
    "    pattern = ' OR '.join(keywords)\n",
    "    return get_timeline(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0f914-8e29-45f9-83bc-958e236b10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kvinn = get_timeline('kvinn*')\n",
    "kvinna = get_timeline('kvinna')\n",
    "korv = get_timeline('korv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada92be8-69e4-4cd6-bccd-a0d0ae168309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_line(timeline, name):\n",
    "    x,y = zip(*timeline)\n",
    "    return go.Line(x=x, y=y, name=name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c16a2d-aebd-4ce0-9518-fb58e59235af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    The first element is the name of the line -- what shows up in the legend of the plot.\n",
    "        \"Name\" : ['search', 'terms', 'in', 'any', 'order'],\n",
    "        \"Name\" : ['also', 'called', 'keywords'],\n",
    "    The second element is a `list` of searchterms.\n",
    "\n",
    "    Note that the `name` and `keywords` / `search terms` are in quotes:\n",
    "        '\n",
    "        \"\n",
    "    You can use either, but they have to match:\n",
    "       \"This is a valid string\"\n",
    "       'This is another valid string'\n",
    "       \"but this will not work' \n",
    "\n",
    "    In the list (denoted by square brackets \"[]\") commas \",\" separate different items in the list.\n",
    "        ['one', 'two' \"three\"] == [\"one\", 'twothree'] \n",
    "\n",
    "    The comma at the end of the lines \" ], \" are used to differentiate between the different lines.\n",
    "    \n",
    "\"\"\"\n",
    "queries = {\n",
    "    \"kvinn*\" : ['kvinn*'],\n",
    "    \"kvinna\" : ['kvinna'],\n",
    "    'The name that shows up in the plot' : ['term1', 'term_2', 'ansikte', 'fler', 'etc']\n",
    "}\n",
    "lines = [make_line(get_or_timeline(keywords), name) for name, keywords in queries.items()]\n",
    "pyo.iplot(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ac3da-b75c-48c0-85c7-4a5cbe3574cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ulrika",
   "language": "python",
   "name": "ulrika"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
