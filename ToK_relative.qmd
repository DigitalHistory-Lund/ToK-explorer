---
title: Tal om Kvinnor (ToK)
jupyter: tok
execute:
    echo: false
    author:
        - Mathias Johansson
        - Ulrika Holgersson
---



```{python}
# !pip install -q tqdm pyriksdagen ipywidgets plotly
```

```{python}
#| scrolled: true
from pyriksdagen.utils import protocol_iterators, download_corpus

from pathlib import Path
from queue import Queue
from lxml import etree
from tqdm.auto import tqdm


import plotly.offline as pyo
import plotly.graph_objs as go
from typing import List, Tuple

from collections import defaultdict
from collections import Counter
from itertools import pairwise

import sqlite3
import json
import gzip
import csv
import re
import os
```



```{python}
parser = etree.XMLParser(remove_blank_text=True)

data_dir = Path('.').resolve() / 'data'
data_dir.mkdir(exist_ok=True)
```

```{python}
if len([file for file in data_dir.iterdir() if file.is_file()]) < 25:
    print('Did not find metadata files. Downloading.')
    download_corpus(partitions=["persons"])

records_data_dir = data_dir / 'records'
if len([subdir for subdir in data_dir.iterdir() if subdir.is_dir()]) < 158:
    print('Did not find protocols files. Downloading.')
    download_corpus(partitions=["records"])
```

```{python}
#| scrolled: true
def datestr_to_int(date_str):
    """Convert YYYY-MM-DD to an int with all digits"""
    year, mon, day = date_str.split('-')
    if not all((len(date_str) == 10, len(year) == 4, len(mon) == 2, len(day) == 2, year.isdigit(), mon.isdigit(), day.isdigit())):
        raise ValueError(f'{date_str=} does not adhere to "YYYY-MM-DD"')

    no_dashes = date_str.replace('-', '')
    if len(no_dashes) != 8:
        raise ValueError
    return int(no_dashes)
```

```{python}
# Loading utterance to (intified) dates
year_path = Path('.') / 'year_data.gzip'
if not year_path.exists():
    !wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1n_RzrYH-ghTF0dIV6tY67r_mVZb2ktyd' -O year_data.gzip
with gzip.open(year_path, 'rt') as f:
    id_to_intdate = {_id: datestr_to_int(date) for date, ids in json.loads(f.read()).items() for _id in ids}
```

```{python}
#| scrolled: true
# ID to gender - default to None if there is no data
id_to_gender = defaultdict(lambda: None)
for row in csv.DictReader(open(data_dir/'person.csv')):
    id_to_gender[row['person_id']]= row['gender']
```

```{python}
# Generator for loading party affiliation with intified date ranges.
def load_person_dates_affiliation():
    for row in csv.DictReader(open(data_dir / 'party_affiliation.csv')):
        if row['start'] is None or len(row['start']) == 0:
            start = 0
        elif len(row['start']) == 4:
            start = datestr_to_int(row['start']+'-01-01')
        elif len(row['start']) == 7:
            start = datestr_to_int(row['start']+'-01')
        else:
            start = datestr_to_int(row['start'])
        if row['end'] is None or len(row['end']) == 0:
            end = 99999999
        elif len(row['end']) == 4:
            end = datestr_to_int(row['end'] + '-12-31')
        elif len(row['end']) == 7:
            end = datestr_to_int(row['end'] + '-31') # Since we are not planning on converting these back to actual days, this works.
        else:
            end = datestr_to_int(row['end'])
        yield (row['person_id'], start, end, row['party'])
```

```{python}
protocols = list(sorted(protocol_iterators(corpus_root="data/", start=1899, end=1941)))
print(len(protocols))
```

```{python}
int(protocols[0].split('/')[1][:4])
```

```{python}
def prepare_roots(protocols):
    for protocol in protocols:
        year = int(protocol.split('/')[1][:4])
        yield etree.parse(protocol, parser).getroot(), year
```

```{python}
def process_root_queue(q: Queue):
    """
    TODO: Extract debate names
    TODO: Extract dates
    """
    while not q.empty():
        c, element, year = q.get()
        if (who:= element.get('who')) is not None:
            u_id = element.get([key for key in element.keys() if key.endswith('}id')][0])
            assert u_id
            prev = element.get('prev')
            nxt = element.get('next')

            text = '\n\n'.join(re.sub(r'\s+' ,' ', seg.text) for seg in element.getchildren())
            yield u_id, prev, nxt, text, who, year
        else:
            for child in element.getchildren():
                if (child.tag.endswith('note') or child.tag.endswith('seg')) and not bool(re.search(r'^\S+dag', child.text)):
                    continue
                q.put((c+1, child, year))
```

```{python}
def extract_all_utterances(protocols):
    q = Queue()
    for root, year in prepare_roots(protocols):
        q.put((0,root, year))
    yield from process_root_queue(q)
```


```{python}
from itertools import islice
def batched(iterable, n, *, strict=False):
    # batched('ABCDEFG', 2) → AB CD EF G
    if n < 1:
        raise ValueError('n must be at least one')
    iterator = iter(iterable)
    while batch := tuple(islice(iterator, n)):
        if strict and len(batch) != n:
            raise ValueError('batched(): incomplete batch')
        yield batch
```

```{python}
pyo.init_notebook_mode(connected=False)
```

```{python}
def enable_plotly_in_cell():

  import IPython
  from plotly.offline import init_notebook_mode
  display(IPython.core.display.HTML('''<script src="/static/components/requirejs/require.js"></script>'''))
  init_notebook_mode(connected=False)
```

```{python}
from collections import defaultdict
```

## Looking at incidence of keyword groups

```{python}

queries = {
    "kvinna" : ['kvinna'],
    "kvinna 1" : ['kvinn*'],
    # 'The name that shows up in the plot' : ['term1', 'term_2', 'ansikte', 'fler', 'etc'],
    #'mans' : ['mans'],
    #'Första sökning*' : ['hon', 'henne*', 'fru*', 'fröken*', 'fröknar*', 'dam', 'dame*', 'mor', 'moder*', 'mamma*', 'mammor*','flick*', 'syster*', 'systrar', 'dotter*', 'döttrar*', 'hustru*','änka*', 'änke*', 'fruntimmer*', 'jungfru*'],

    # Non work-related titles
    'Kvinna 2' : ['hon', 'henne*', 'fru',  'dam', 'dame*', 'mor', 'moder', 'mamma*', 'mammor*','flick*', 'syster*', 'systrar', 'dotter*', 'döttrar*', 'hustru*','änka*', 'änke*', 'fruntimmer*', ], #

    # Work-related and possibly work-related titles
    'Kvinna 3' : [
                'fröken*', 'fröknar*', 'jungfru*',
                'arbeterska*', 'arbeterskor*','fabriksarbeterka*', 'fabriksarbeterskor*','hushållerska*', 'hushållerskor*','lärarinna*', 'lärarinnor*', 'småskolelärarinna*', 'småskolelärarinnor*', 'mjölkerska*', 'mjölkerskor*',
                 'sjuksköterska*', 'sjuksköterskor*','sköterska*', 'sköterskor*', 'tjänarinna*', 'tjänarinnor*', 'tjänstekvinna*', 'tjänstekvinnor*', 'tjänsteflick*', 'tjänstepiga*', 'tjänstepigor*', 'sömmerska*',
                 'sömmerskor*', 'uppasserska*', 'uppaskerskor*', 'kokerska*', 'kokerskor*' ,
                'hon', 'henne*',
                'mor', 'moder*', 'mamma*', 'mammor*', 'mödra*',
                'syster*', 'systrar',
                'flick*',
                'änka*', 'änke*',
                'fröken*', 'fröknar*',
                'dam', 'dame*',
                'hustru*',
                'dotter*', 'döttrar*',
                'fruntimmer*',
                'piga*', 'pigor*',
                'flick*',
                'hembiträde*',
                'jungfru*',
                'arbeterska*', 'arbeterskor*',
                'fabriksarbeterka*', 'fabriksarbeterskor*',
                'hushållerska*', 'hushållerskor*',
                'lärarinna*', 'lärarinnor*', 'småskolelärarinna*', 'småskolelärarinnor*',
                'mjölkerska*', 'mjölkerskor*',
                'sjuksköterska*', 'sjuksköterskor*', 'sköterska*', 'sköterskor*',
                'tjänarinna*', 'tjänarinnor*', 'tjänstekvinna*', 'tjänstekvinnor*', 'tjänsteflick*', 'tjänstepiga*', 'tjänstepigor*',
                'sömmerska*', 'sömmerskor*',
                'uppasserska*', 'uppaskerskor*',
                'kokerska*', 'kokerskor*'],
    #  'Pronomen' : ['hon', 'henne*'],
    #  'Moder' : ['mor', 'moder*', 'mamma*', 'mammor*', 'mödra*'],
    #  'Syster' : ['syster*', 'systrar',],
    #  'Flicka' : ['flick*'],
    #  'Änka' : ['änka*', 'änke*'],
    #  'Fröken' : ['fröken*', 'fröknar*'],
    #  'Dam' : ['dam', 'dame*'],
    #  'Hustru' : ['hustru*'],
    #  'Dotter' : ['dotter*', 'döttrar*'],
    #  'Fruntimmer*' : ['fruntimmer*'],
    #  'piga' : ['piga*', 'pigor*'],
    #  'Flicka' : ['flick*'],
    #  'Hembiträde' : ['hembiträde*'],
    #  'Jungfru' : ['jungfru*'],
    #  'Arbeterska' : ['arbeterska*', 'arbeterskor*'],
    #  'Fabriksarbeterska' : ['fabriksarbeterka*', 'fabriksarbeterskor*'],
    #  'Hushållerska' : ['hushållerska*', 'hushållerskor*'],
    #  'Lärarinna' : ['lärarinna*', 'lärarinnor*', 'småskolelärarinna*', 'småskolelärarinnor*'],
    #  'Mjökerska' : ['mjölkerska*', 'mjölkerskor*'],
    #  'Sjuksköterska' : ['sjuksköterska*', 'sjuksköterskor*', 'sköterska*', 'sköterskor*'],
    #  'Tjänarinna' : ['tjänarinna*', 'tjänarinnor*', 'tjänstekvinna*', 'tjänstekvinnor*', 'tjänsteflick*', 'tjänstepiga*', 'tjänstepigor*'],
    #  'Sömmerska' : ['sömmerska*', 'sömmerskor*'],
    #  'Uppaskerska' : ['uppasserska*', 'uppaskerskor*'],
    #  'Kokerska' : ['kokerska*', 'kokerskor*'],
}


#
#   Edit the above and run cell (shift + enter) to update plot
#
```

# Relative word frequencies

Since the annual number of utterances shift greatly between 1919 and 1920
-- whereas the number uttered words remains fairly stable -- we need to look
at relative word frequencies instead.

```{python}
rel_db = './rel.dn'
if not os.path.exists(rel_db):

  all_utterances = list(  tqdm(extract_all_utterances(protocols), total=701_218))

  with sqlite3.connect(rel_db) as conn:
      cur = conn.cursor()
      cur.execute('CREATE TABLE utterance (id str primary key, prev text, next text, who text, year int, date int, gender text, party text)')
      # cur.execute("PRAGMA compile_options LIKE '%SQLITE_ENABLE_FTS5%';")



      cur.execute('CREATE TABLE affiliation (who text, start int, end int, party text)')

      cur.execute('CREATE index next_index on utterance(next)')
      cur.execute('CREATE index who_index on utterance(who)')
      cur.execute('CREATE index year_index on utterance(year)')

      cur.executemany('INSERT INTO affiliation (who, start, end, party) values (?,?,?,?)', load_person_dates_affiliation())
      cur.execute('CREATE index aff_index on affiliation(who)')

      cur.execute('CREATE table word (id integer primary key autoincrement, utterance_id, word text, kvinna int, kvinna1 int , kvinna2 int, kvinna3 int)')
      cur.execute('CREATE index word_index_word on word(word)')

      cur.execute('CREATE index word_index_utteranceid on word(utterance_id)')

      data = []
      for batch in tqdm(batched(all_utterances, 50_000), total=len(all_utterances)//50_000):
          data = [
              {'id':u_id,
              'prev':prev,
              'next':nxt,
              'content':text,
              'reverse_content':text[::-1],
              'who':who,
              'year':year,
              'gender': id_to_gender[who],
              'date' : id_to_intdate[u_id]
              } for u_id, prev, nxt, text, who, year in batch]

          cur.executemany('INSERT INTO utterance (id, prev, next, who, year, gender, date) values (:id, :prev, :next, :who, :year, :gender, :date)', data)

          word_data = [{'utterance_id': d['id'], 'word': word} for d in data for word in d['content'].split()]
          cur.executemany('INSERT INTO word (utterance_id, word) values (:utterance_id, :word)', word_data)

          conn.commit()

      # TODO: Add speaker metadata
      cur.execute("""
      UPDATE utterance
      SET party = (
          SELECT party
          FROM affiliation
          WHERE utterance.who = affiliation.who
            AND date BETWEEN start AND end
      )
      WHERE EXISTS (
          SELECT 1
          FROM affiliation
          WHERE utterance.who = affiliation.who
            AND date BETWEEN start AND end
      )
      """)

      for key, patterns in tqdm(queries.items(), desc='Tagging relevant words'):
          col_name = key.replace(' ','').lower()
          for pattern in patterns:
              pattern = pattern.replace('*', '%')
              cur.execute(f'''
              UPDATE word
              SET {col_name} = 1
              WHERE word like ?
              ''', (pattern,))


      # Table for baseline w/ indexi
      cur.execute('CREATE table baseline (id integer primary key autoincrement, who text, year int, gender text, party text, count int, kvinna int, kvinna1, int, kvinna2 int, kvinna3 int)')
      cur.execute('CREATE index baseline_ygp_index on baseline(year, gender, party)')
      cur.execute('CREATE index baseline_gp_index on baseline(gender, party)')
      cur.execute('CREATE index baseline_yp_index on baseline(year, party)')
      cur.execute('CREATE index baseline_yg_index on baseline(year, gender)')
      cur.execute('CREATE index baseline_y_index on baseline(year)')
      cur.execute('CREATE index baseline_g_index on baseline(gender)')
      cur.execute('CREATE index baseline_p_index on baseline(party)')

      """
      select who, year, gender, party, count(*), sum from utterance as u join word as w on u.id == w.utterance_id group by who, year, gender, party


      """

      cur.execute('''
      INSERT INTO baseline (who, year, gender, party, count, kvinna, kvinna1, kvinna2, kvinna3)
      SELECT who, year, gender, party, count(*), sum(kvinna), sum(kvinna1), sum(kvinna2), sum(kvinna3)
      FROM utterance AS u
      JOIN word AS w ON u.id = w.utterance_id
      GROUP BY who, year, gender, party
      ''')
      conn.commit()
```

```{python}
"""
First, let's recreate the decomposition on utterance level per year
to make sure that the methodology is sound.
"""

with sqlite3.connect(rel_db) as conn:
    cur = conn.cursor()
    cur.execute(
    """
    select year, sum(uc), sum(k), sum(k1), sum(k2), sum(k3) from
      (
      select
        year,
        1 as uc ,
        max(kvinna) as k,
        max(kvinna1) as k1,
        max(kvinna2) as k2,
        max(kvinna3) as k3
      from
        utterance as u
      join
        word as w
      on
        u.id == w.utterance_id
      group by
        year,
        utterance_id
      )
    group by year
    """)
    results = cur.fetchall()
    x, y_uc, y_k, y_k1, y_k2, y_k3 = zip(*results)
    lines = [go.Scatter(mode='lines', x=x, y=y_uc, name='utterance count'),
             go.Scatter(mode='lines', x=x, y=y_k, name='kvinna'),
             go.Scatter(mode='lines', x=x, y=y_k1, name='kvinna1'),
             go.Scatter(mode='lines', x=x, y=y_k2, name='kvinna2'),
             go.Scatter(mode='lines', x=x, y=y_k3, name='kvinna3'),
            ]
    pyo.iplot({
        'data':lines,
                    'layout':{
                'title':{
                    'text': 'Sanity check: Recreating the "Counting Utterances with different keyword compositions."',
                    'xanchor': 'center',
                    'x':0.5
                }, }})
```

```{python}
# Perfect.

"""
Now we can recreate it with word frequencies and relative word frequencies.
"""

with sqlite3.connect(rel_db) as conn:
    cur = conn.cursor()
    cur.execute(
    """
      select
        year,
        sum(b.count) as uc,
        sum(kvinna) as k,
        cast(sum(kvinna )as real)/ sum(b.count) as kr,
        sum(kvinna1) as k1,
        cast(sum(kvinna1) as real)/ sum(b.count) as k1r,
        sum(kvinna2) as k2,
        cast(sum(kvinna2) as real)/ sum(b.count) as k2r,
        sum(kvinna3) as k3,
        cast(sum(kvinna3) as real)/ sum(b.count) as k3r
      from
        baseline as b
      group by
        year
    """)
    results = cur.fetchall()
    x, y_uc, y_k,y_kr, y_k1, y_k1r, y_k2,y_k2r, y_k3, y_k3r = zip(*results)
    lines = [
            go.Scatter(mode='lines', x=x, y=y_uc, name='word count'),
             go.Scatter(mode='lines', x=x, y=y_k, name='kvinna'),
             go.Scatter(mode='lines', x=x, y=y_k1, name='kvinna1'),
             go.Scatter(mode='lines', x=x, y=y_k2, name='kvinna2'),
             go.Scatter(mode='lines', x=x, y=y_k3, name='kvinna3'),
            ]
    pyo.iplot({
        'data':lines,
                              'layout':{
                'title':{
                    'text': 'Counting keywords by category.',
                    'xanchor': 'center',
                    'x':0.5
                }, }}
    )

    lines = [
             go.Scatter(mode='lines', x=x, y=y_kr, name='kvinna'),
             go.Scatter(mode='lines', x=x, y=y_k1r, name='kvinna1'),
             go.Scatter(mode='lines', x=x, y=y_k2r, name='kvinna2'),
             go.Scatter(mode='lines', x=x, y=y_k3r, name='kvinna3'),
            ]
    pyo.iplot({
        'data':lines,
                              'layout':{
                'title':{
                    'text': 'Relative keyword frequencies by category.',
                    'xanchor': 'center',
                    'x':0.5
                }, }}
    )
```

```{python}
# Interesting that no big differences show up here.
"Let's add the gender dimension."
with sqlite3.connect(rel_db) as conn:
    cur = conn.cursor()
    cur.execute(
    """
      select
        year,
        gender,
        sum(b.count) as uc,
        sum(kvinna) as k,
        cast(sum(kvinna )as real)/ sum(b.count) as kr,
        sum(kvinna1) as k1,
        cast(sum(kvinna1) as real)/ sum(b.count) as k1r,
        sum(kvinna2) as k2,
        cast(sum(kvinna2) as real)/ sum(b.count) as k2r,
        sum(kvinna3) as k3,
        cast(sum(kvinna3) as real)/ sum(b.count) as k3r
      from
        baseline as b
      where gender is not null
      group by
        year, gender
      order by year, gender
    """)
    results = cur.fetchall()

    by_gender = defaultdict(list)
    for row in results:
        year, gender, *values = row
        by_gender[gender].append((year, *values))


    lines = []
    relines = []
    for gender, data in by_gender.items():

        x, y_uc, y_k,y_kr, y_k1, y_k1r, y_k2,y_k2r, y_k3, y_k3r = zip(*data)


        lines += [
              go.Scatter(mode='lines', x=x, y=y_uc, name=f'{gender}: word count'),
              go.Scatter(mode='lines', x=x, y=y_k, name=f'{gender}: kvinna'),
              go.Scatter(mode='lines', x=x, y=y_k1, name=f'{gender}: kvinna1'),
              go.Scatter(mode='lines', x=x, y=y_k2, name=f'{gender}: kvinna2'),
              go.Scatter(mode='lines', x=x, y=y_k3, name=f'{gender}: kvinna3'),
              ]

        relines += [
              go.Scatter(mode='lines', x=x, y=y_kr, name=f'{gender}: kvinna'),
              go.Scatter(mode='lines', x=x, y=y_k1r, name=f'{gender}: kvinna1'),
              go.Scatter(mode='lines', x=x, y=y_k2r, name=f'{gender}: kvinna2'),
              go.Scatter(mode='lines', x=x, y=y_k3r, name=f'{gender}: kvinna3'),
              ]

    pyo.iplot({
        'data':lines
    ,
                              'layout':{
                'title':{
                    'text': 'Counting keyword categories by gender.',
                    'xanchor': 'center',
                    'x':0.5
                }, }}
    )
    pyo.iplot({
        'data':relines,
                              'layout':{
                'title':{
                    'text': 'Relative keyword categories frequencies by gender.',
                    'xanchor': 'center',
                    'x':0.5
                }, }}
    )
```

```{python}
# Big difference here. Interesting.
# Interesting that no big differences show up here.
"Let's add the party dimension."
with sqlite3.connect(rel_db) as conn:
    cur = conn.cursor()
    cur.execute(
    """
      select
        year,
        party,
        sum(b.count) as uc,
        sum(kvinna) as k,
        cast(sum(kvinna )as real)/ sum(b.count) as kr,
        sum(kvinna1) as k1,
        cast(sum(kvinna1) as real)/ sum(b.count) as k1r,
        sum(kvinna2) as k2,
        cast(sum(kvinna2) as real)/ sum(b.count) as k2r,
        sum(kvinna3) as k3,
        cast(sum(kvinna3) as real)/ sum(b.count) as k3r
      from
        baseline as b
      where party is not null
      group by
        year, party
      order by year, party
    """)
    results = cur.fetchall()

    by_party = defaultdict(list)
    for row in results:
        year, party, *values = row
        by_party[party].append((year, *values))


    k = []
    k1 = []
    k2 = []
    k3 = []
    for party, data in by_party.items():

        x, y_uc, y_k,y_kr, y_k1, y_k1r, y_k2,y_k2r, y_k3, y_k3r = zip(*data)



        k.append(go.Scatter(mode='lines', x=x, y=y_kr, name=f'{party}'),)
        k1.append(go.Scatter(mode='lines', x=x, y=y_k1r, name=f'{party}'),)
        k2.append(go.Scatter(mode='lines', x=x, y=y_k2r, name=f'{party}'),)
        k3.append(go.Scatter(mode='lines', x=x, y=y_k3r, name=f'{party}'),)


    pyo.iplot({
        'data':k    ,
        'layout':{
                'title':{
                    'text': 'Relative frequencies of "kvinna" by party',
                    'xanchor': 'center',
                    'x':0.5
                }, }}
    )
    pyo.iplot({
        'data':k1    ,
        'layout':{
                'title':{
                    'text': 'Relative frequencies of "kvinna 1" by party',
                    'xanchor': 'center',
                    'x':0.5
                }, }}
    )
    pyo.iplot({
        'data':k2    ,
        'layout':{
                'title':{
                    'text': 'Relative frequencies of "kvinna 2" by party',
                    'xanchor': 'center',
                    'x':0.5
                }, }}
    )
    pyo.iplot({
        'data':k3    ,
        'layout':{
                'title':{
                    'text': 'Relative frequencies of "kvinna 3" by party',
                    'xanchor': 'center',
                    'x':0.5
                }, }}
    )
```

```{python}
def boxes(lower=1900, upper=1940):
    with sqlite3.connect(rel_db) as conn:

        cur = conn.cursor()

        genders = [ans[0] for ans in cur.execute('select distinct gender from utterance')]

        for gender in genders:
            ark = cur.execute(
                f"""select who, party,
        cast(sum(kvinna )as real)/ sum(b.count) as kr,
        cast(sum(kvinna1) as real)/ sum(b.count) as k1r,
        cast(sum(kvinna2) as real)/ sum(b.count) as k2r,
        cast(sum(kvinna3) as real)/ sum(b.count) as k3r
        from baseline as b
        where gender == "{gender}" and year between {lower} and {upper} group by who
                """).fetchall()
            if ark == []:
                continue

            who, x, yk, yk1, yk2, yk3 = zip(*ark)
            yield go.Bar(x=x, y=yk), go.Bar(x=x, y=yk1), go.Bar(x=x, y=yk2), go.Bar(x=x, y=yk3)

years = list(range(1900, 1941, 10))
full = [(1900, 1940)] + list(pairwise(years))

for start, end in full:
    k = []
    k1 = []
    k2 = []
    k3 = []
    for bk, bk1, bk2, bk3 in boxes(start, end):
        k.append(bk)
        k1.append(bk1)
        k2.append(bk2)
        k3.append(bk3)
    for name, lines in [('kvinna', k), ('kvinna 1', k1), ('kvinna 2', k2), ('kvinna 3', k3)]:
      pyo.iplot({'data' : k,
          'layout':{
              'title':{
                  'text': name + ' ' + str(start) + '-' + str(end),
                  'xanchor': 'center',
                  'x':0.5
              }, }})
```


